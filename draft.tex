\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{ADLR WS21 - Project Proposal Team 04\\
}

\author{\IEEEauthorblockN{Marc Hauck}
\IEEEauthorblockA{\textit{Robotics, Cognition, Intelligence} \\
\textit{Technical University of Munich}\\
Munich, Germany \\
ge65qoy@mytum.de}
\and
\IEEEauthorblockN{Baris Tura}
\IEEEauthorblockA{\textit{Robotics, Cognition, Intelligence} \\
\textit{Technical University of Munich}\\
Munich, Germany \\
baris.tura@tum.de}}

\maketitle

\section{Objective}
Motion planning lies at the core of robotics. However, traditional methods are not only demanding in terms of computation, but also require prior knowledge of the environment. The real conditions of the environment in which a robot arm operates may be well outside of what the environment model entails, making swift responsiveness to unexpected obstacles a desirable trait for robots. Learning methods were found to be successful in unseen environments and in this work, we aim to harness reinforcement learning algorithms to guide a robotic arm through a dynamic environment where the instantaneous locations and trajectories of obstacles are unknown to the agent. Hereby, we aim to supplement local guidance of reinforcement learning with a global guidance algorithm, so as to keep the balance of exploitation and exploration. Whereas deterministic real-world environments are not in need of new technological advances, there is much work to be done in unknown environments, and we hope consider this an important matter as it spans a wide range of applications such as HCI.

\section{Related Work}

Previous works consist of motion planning in static environments for joint robots, and motion planning in dynamic environments for mobile robots. Jurgenson et al. propose a DDPG based algorithm with expert knowledge for a planar RRR robot in a static yet unknown environment. The claim is that supervised learning is heterogeneous in terms of data distribution and lacks sufficient data close to object boundaries; and that imitation learning leaves no room for exploration, especially in unseen environments as the expert never collides with the objects. Their results obtained with the expert supported algorithm, named DDPG-MP, show superior results to those of classic DDPG and HER algorithms. Wang et al. guide an agent through a 2D environment comprising of static and dynamic obstacles using ConvNets for scene understanding and an LSTM+MLP network for action selection. Here, they make use of A* search as global guidance to enforce minimal traversal through the environment while still avoiding the dynamic obstacles. All the obstacles are unknown a priori, and are percieved within a certain field of view by the robot. For action selection, classic DDQN algorithm is used in conjunction with an LSTM network to have temporal reasoning. They name the approach Globally Guided Reinforcement Learning and obtain state-of-the-art results. 

\section{Technical Outline} To begin, we will to guide a simple point robot through a grid world with static obstacles using different algorithms such as DDPG and HER. By doing so we hope to observe the effects different algorithms have on this particular application. Thereafter, we are going to add global guidance to the frame and see its impact. We consider expert knowledge in the form of global guidance to be a proper choice, as the robot will always have a goal, regardless of how unknown the environment is. Building on that, we plan to transition from a point robot to one with three joints, while keeping the environment static and planar. By doing so, we hope to create the backbone of our model, deciding on a tentative algorithm and network structure. On top of that, we are going to compare the results we obtain with [1], as they state that a global guidance may improve their results. Having successfully guided the joint robot in the static environment, we aim to introduce motion to the obstacles. At this point, we foresee large changes to our previous model...........................

\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
\end{thebibliography}

\end{document}
